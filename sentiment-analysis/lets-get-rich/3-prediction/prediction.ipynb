{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuObdgt3zgPv",
        "outputId": "b7fb910a-ca18-4b48-d2e8-bba091fd4867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Berhasil: Semua komponen siap digunakan!\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "def load_joblib_from_github(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status() # Cek apakah URL valid/bisa diakses\n",
        "\n",
        "        content = response.content\n",
        "\n",
        "        # Deteksi Git LFS pointer (GitHub tidak mengirim file asli jika LFS aktif tanpa kuota)\n",
        "        if content.startswith(b\"version https://git-lfs.github.com\"):\n",
        "            return \"ERROR_LFS\"\n",
        "\n",
        "        # Gunakan joblib untuk me-load dari buffer memori (BytesIO)\n",
        "        return joblib.load(BytesIO(content))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Gagal memuat file dari: {url}\\nError: {e}\")\n",
        "        return None\n",
        "\n",
        "# ===== URL (Pastikan URL \"Raw\") =====\n",
        "base_url = \"https://raw.githubusercontent.com/asepsr37/data-and-machine-learning/main/sentiment-analysis/lets-get-rich/model-sentiment/\"\n",
        "\n",
        "url_model = base_url + \"model_sentiment_lgr.pkl\"\n",
        "url_tfidf = base_url + \"tfidf_vectorizer_lgr.pkl\"\n",
        "url_le    = base_url + \"label_encoder_lgr.pkl\"\n",
        "\n",
        "# ===== PROSES LOAD =====\n",
        "model = load_joblib_from_github(url_model)\n",
        "tfidf = load_joblib_from_github(url_tfidf)\n",
        "label_encoder = load_joblib_from_github(url_le)\n",
        "\n",
        "# Cek apakah ada masalah Git LFS\n",
        "if model == \"ERROR_LFS\":\n",
        "    print(\"⚠️ WARNING: File di GitHub terdeteksi sebagai Git LFS pointer.\")\n",
        "    print(\"GitHub Raw tidak bisa mendownload file LFS yang besar secara langsung.\")\n",
        "    print(\"Solusi: Upload file ke Google Drive atau hosting lain yang mendukung direct download.\")\n",
        "else:\n",
        "    print(\"✅ Berhasil: Semua komponen siap digunakan!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alur Prediksi Data Baru\n",
        "- Input: Teks mentah dari user.\n",
        "\n",
        "1. tfidf.pkl (The Translator): Teks diubah menjadi deretan angka. Tanpa ini, model \"buta\" karena ia hanya bisa membaca matematika, bukan kata-kata.\n",
        "\n",
        "2. model.pkl (The Brain): Angka tadi diproses oleh otak Logistic Regression. Hasil keluarnya adalah angka indeks (misal: 0).\n",
        "\n",
        "3. le.pkl (The Spokesperson): Angka 0 tadi diterjemahkan kembali menjadi kata-kata yang kita mengerti (misal: \"negative\")."
      ],
      "metadata": {
        "id": "YsnGNrNE0yn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "# 1. Fungsi Cleaning (Wajib sama dengan saat training)\n",
        "def cleaningtext(text):\n",
        "    text = re.sub(r\"@[A-Za-z0-9]+\", \"\", text)       # Hapus mention\n",
        "    text = re.sub(r\"#[A-Za-z0-9]+\", \"\", text)       # Hapus hashtag\n",
        "    text = re.sub(r\"RT[\\s]\", \"\", text)              # Hapus RT\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)             # Hapus link\n",
        "    text = re.sub(r\"[0-9]+\", \"\", text)              # Hapus angka\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)             # Hapus simbol/emoji\n",
        "    text = text.replace(\"\\n\", \" \")                  # Hapus baris baru\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    text = text.strip().lower()                     # Case folding\n",
        "    return text\n",
        "\n",
        "# 2. Fungsi Prediksi Utama\n",
        "def predict_lgr_sentiment(user_review):\n",
        "    if model is None or tfidf is None or label_encoder is None:\n",
        "        return \"Gagal: Model belum dimuat sempurna.\"\n",
        "\n",
        "    # A. Preprocessing\n",
        "    clean_text = cleaningtext(user_review)\n",
        "\n",
        "    # B. Transformasi ke TF-IDF\n",
        "    # Kita masukkan ke dalam list [clean_text] karena TF-IDF butuh iterable\n",
        "    vectorized_text = tfidf.transform([clean_text])\n",
        "\n",
        "    # C. Prediksi Indeks\n",
        "    prediction_idx = model.predict(vectorized_text)\n",
        "\n",
        "    # D. Decode Indeks ke Label Teks\n",
        "    label = label_encoder.inverse_transform(prediction_idx)[0]\n",
        "\n",
        "    # E. (Opsional) Ambil Skor Probabilitas\n",
        "    prob = model.predict_proba(vectorized_text).max()\n",
        "\n",
        "    return label, prob"
      ],
      "metadata": {
        "id": "SoSlAxax03OT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== COBA SISTEM =====\n",
        "print(\"-\" * 30)\n",
        "input_user = \"This Games is so bad, i dont want play again\"\n",
        "hasil, skor = predict_lgr_sentiment(input_user)\n",
        "\n",
        "print(f\"Ulasan: {input_user}\")\n",
        "print(f\"Hasil Analisis: {hasil.upper()}\")\n",
        "print(f\"Tingkat Keyakinan Model: {skor*100:.2f}%\")\n",
        "print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7HUWhqF2T4p",
        "outputId": "6f31a73e-0a7f-4356-f7ca-b31638b27389"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Ulasan: This Games is so bad, i dont want play again\n",
            "Hasil Analisis: NEGATIVE\n",
            "Tingkat Keyakinan Model: 82.41%\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLAZkSye2a3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}